{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "!rm -rf shakespeare_data/plays_xml\n",
    "!unzip -P PASSWORD shakespeare_data/plays.zip -d shakespeare_data/plays_xml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "from lxml import etree\n",
    "import itertools\n",
    "from datascience import *\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Social Network Analysis: NetworkX"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mark Algee-Hewitt looks at thousands of plays across centuries. But as we've learned so far, to do this we first have to figure out how to calculate the metrics we're interested in for a single text. Let's take a look at a single play. Luckily, there are databases that exists that have already annotated a lot of plays in a markup language called XML. Especially well researched corpora have extensive metadata. We'll look at the Shakespeare corpus with data obtained from https://www.playshakespeare.com/ .\n",
    "\n",
    "We'll start by looking at *Othello*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with open(\"shakespeare_data/plays_xml/othello_ps_v3.xml\") as f:\n",
    "    othello_xml = etree.fromstring(f.read().encode())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we're trying to build a network we need two things: 1) nodes and 2) edges. For Algee-Hewitt, and for us today, that means we need to know the characters in *Othello*, and with whom they communicate. We'd also like to know how often that specific interaction occurs.\n",
    "\n",
    "We can get all elements of the XML tree by `iter`ating over all the nodes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "all_elements = list(othello_xml.iter())\n",
    "all_elements"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That's a lot of information! Let's grab out all of the speakers. All the `speaker` elements will have a `text` attribute that has their actual name, or abbreviation of their name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "[e.text for e in all_elements if e.tag == \"speaker\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To get a unique list we'll use `set`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "set([e.text for e in all_elements if e.tag == \"speaker\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great start! In Network Analysis there are two fundamental principles. A ***node*** is an entity, it can have relationships with other entities. In literature, this is often a character, but it could be a Twitter user, organization, geographic location, or even words!\n",
    "\n",
    "We may be interested in a node's properties. If it's a character, we may want to know how often they speak, age, etc. We can add this to the network as further layers.\n",
    "\n",
    "The second concept is an ***edge***. An edge connects nodes. We're foremost interested in the volume of connections between nodes. For literature, this would be the number of times two characters interact.\n",
    "\n",
    "As we learned from Moretti and our readings for today, this is a very difficult task for most texts. Where does on character's speech end and another's begin? Luckily, in plays this is slightly easier to identify (though still not perfectly clear).\n",
    "\n",
    "For Shakespeare, we'll settle for them being present in the same *scene*. If they're in the same scene together, we'll increase our measure of their interaction.\n",
    "\n",
    "Thus for each character we want to know how many lines the speak in the entire play, along with which scenes they appear in. We can then collate this wil the other characters.\n",
    "\n",
    "The `get_cast_dict` function below will parse the XML data and extract this information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_cast_dict(all_elements):\n",
    "    '''\n",
    "    returns a dictionary with the total number of lines and scenes a character appears in\n",
    "    '''\n",
    "    \n",
    "    cast_dict = {}\n",
    "    \n",
    "    # first get a unique set of all characters appearing in the play\n",
    "    for c in set([e.text for e in all_elements if e.tag == \"speaker\"]):\n",
    "        cast_dict[c] = {\"num_lines\": 0,\n",
    "                        \"scenes\": []}\n",
    "    \n",
    "    # extract all scene elements from the xml\n",
    "    scenes = [e for e in all_elements if e.tag == \"scene\"]\n",
    "    \n",
    "    # iterate through each scene\n",
    "    for sc in scenes:\n",
    "        \n",
    "        # grab all the speeches in the scene\n",
    "        speeches = [s for s in sc.getchildren() if s.tag == \"speech\"]\n",
    "        \n",
    "        # iterate through speeches\n",
    "        for s in speeches:\n",
    "            \n",
    "            # increment number of lines for the speaker\n",
    "            cast_dict[s.find(\"speaker\").text][\"num_lines\"] += len(s.findall(\"line\"))\n",
    "            \n",
    "        # find all the speaker for each speech    \n",
    "        speakers = [s.find(\"speaker\").text for s in speeches]\n",
    "        \n",
    "        # add the title of the scene for each speaker appearing in the scene\n",
    "        for s in set(speakers):\n",
    "            cast_dict[s][\"scenes\"].append(sc.find(\"scenetitle\").text)\n",
    "        \n",
    "    # reassign scenes to only a unique set\n",
    "    for c in cast_dict.keys():\n",
    "        cast_dict[c][\"scenes\"] = list(set(cast_dict[c][\"scenes\"]))\n",
    "            \n",
    "    return cast_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cast_dict = get_cast_dict(all_elements)\n",
    "cast_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That's all we need to make a basic network and do some analysis! We have all the character names and the scenes in which they appear. We can collate some of this information to find out in which scenes certain characters appear together. This will happen in our `make_graph` function.\n",
    "\n",
    "The `NetworkX` Python library will parse this dictionary for us to make a graph object. Let's write a function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def make_graph(c_dict):\n",
    "    '''\n",
    "    This function accepts a dictionary with number of lines and scenes to create a\n",
    "    NetworkX graph object\n",
    "    '''\n",
    "    # setup graph object\n",
    "    G = nx.Graph()\n",
    "    \n",
    "    # add nodes with attributes of number of lines and scenes\n",
    "    for c in c_dict.keys():\n",
    "        if c_dict[c][\"num_lines\"] > 0:\n",
    "            G.add_node(\n",
    "                c,\n",
    "                number_of_lines=c_dict[c][\"num_lines\"],\n",
    "                scenes=c_dict[c][\"scenes\"]\n",
    "            )\n",
    "\n",
    "    # make edges by iterating over all combinations of nodes\n",
    "    for (node1, data1), (node2, data2) in itertools.combinations(G.nodes(data=True), 2):\n",
    "\n",
    "        # count scenes together by getting union of their sets\n",
    "        scenes_together = len(set(data1['scenes']) & set(data2['scenes']))\n",
    "        \n",
    "        if scenes_together:\n",
    "            # add more weight for more scenes together\n",
    "            G.add_edge(node1, node2, weight=scenes_together)\n",
    "            \n",
    "    return G"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "G = make_graph(cast_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can graph this using `matplotlib`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# nodes should be sized by number of lines\n",
    "node_size = [data['number_of_lines'] for __, data in G.nodes(data=True)]\n",
    "node_color = 'blue'\n",
    "\n",
    "plt.figure(figsize=(13,8))  # make the figure size a little larger\n",
    "plt.axis('off')  # remove the axis, which isn't meaningful in this case\n",
    "plt.title(\"Othello's Social Network\", fontsize=20)\n",
    "\n",
    "# The 'k' argument determines how spaced out the nodes will be from\n",
    "# one another on the graph.\n",
    "pos = nx.spring_layout(G, k=0.5)\n",
    "\n",
    "nx.draw_networkx(\n",
    "    G,\n",
    "    pos=pos,\n",
    "    node_size=node_size,\n",
    "    node_color=node_color,\n",
    "    edge_color='gray',  # change edge color\n",
    "    alpha=0.3,  # make nodes more transparent to make labels clearer\n",
    "    font_size=14,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our graph, `G`, is a powerful object. We can calculate many of the standard network analysis statistics. There are various measures of centrality, many of which were referenced in the reading."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "network_tab = Table()\n",
    "network_tab.append_column(label=\"Characters\", values=[c for c in sorted(cast_dict.keys())])\n",
    "network_tab.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wikipedia defines \"[degree centrality](https://en.wikipedia.org/wiki/Centrality#Degree_centrality)\":\n",
    ">Historically first and conceptually simplest is degree centrality, which is defined as the number of links incident upon a node (i.e., the number of ties that a node has)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dc = [x[1] for x in sorted(nx.degree_centrality(G).items(), key=lambda x: x[0])]\n",
    "network_tab.append_column(label=\"Degree Centrality\", values=dc)\n",
    "network_tab.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wikipedia defines \"[betweeness centrality](https://en.wikipedia.org/wiki/Centrality#Betweenness_centrality)\":\n",
    "\n",
    ">Betweenness is a centrality measure of a vertex within a graph (there is also edge betweenness, which is not discussed here). Betweenness centrality quantifies the number of times a node acts as a bridge along the shortest path between two other nodes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "bc = [x[1] for x in sorted(nx.betweenness_centrality(G).items(), key=lambda x: x[0])]\n",
    "network_tab.append_column(label=\"Betweenness Centrality\", values=bc)\n",
    "network_tab.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wikipedia defines \"[eigenvector centrality](https://en.wikipedia.org/wiki/Centrality#Eigenvector_centrality)\":\n",
    "> Eigenvector centrality (also called eigencentrality) is a measure of the influence of a node in a network. It assigns relative scores to all nodes in the network based on the concept that connections to high-scoring nodes contribute more to the score of the node in question than equal connections to low-scoring nodes.\n",
    "\n",
    ">$x_v = \\frac{1}{\\lambda} \\sum_{t \\in M(v)}x_t = \\frac{1}{\\lambda} \\sum_{t \\in G} a_{v,t}x_t$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ec = [x[1] for x in sorted(nx.eigenvector_centrality(G).items(), key=lambda x: x[0])]\n",
    "network_tab.append_column(label=\"Eigenvector Centrality\", values=ec)\n",
    "network_tab.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Challenge\n",
    "\n",
    "What is the overlap ((rank) correlation) between the three measurements presented above? What does that mean for the play?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bonus: Making a prettier graph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`matplotlib` isn't always the most beautiful option. A popular way of visualizing networks is by using Javascript's [D3](https://d3js.org/) library. Luckily, `networkx` allows us to export the network information to JSON:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from networkx.readwrite import json_graph\n",
    "import json\n",
    "\n",
    "d3_data = json_graph.node_link_data(G)\n",
    "d3_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can then add this to a D3 template:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "with open('network.html', 'r') as f:\n",
    "    net_html = f.read()\n",
    "\n",
    "pattern = re.compile(r'(<script type=\"application/json\" id=\"net\">)(\\s*.*)')\n",
    "net_html = net_html.replace(re.findall(pattern, net_html)[-1][-1].strip(), json.dumps(d3_data).strip())\n",
    "\n",
    "with open('network.html', 'w') as f:\n",
    "    f.write(net_html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll then `IFrame` in the HTML file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from IPython.display import IFrame\n",
    "IFrame('network.html', width=700, height=900)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Gini Coefficient\n",
    "\n",
    "Algee-Hewitt was calculating the gini coefficient of the eigenvector centralities. He essentially wanted to know whether importance in a network was evenly distributed, or concentrated in the hands of a few. The lower the gini coefficient, the more equal the distribution, the closer to 1, the closer one gets to complete inequality. I've found a function online that will calculate the gini coefficient for you!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def gini(array):\n",
    "    \"\"\"Calculate the Gini coefficient of a numpy array.\"\"\"\n",
    "    # https://github.com/oliviaguest/gini\n",
    "    array = np.sort(array) # values must be sorted\n",
    "    index = np.arange(1, array.shape[0] + 1) # index per array element\n",
    "    n = array.shape[0] # number of array elements\n",
    "    return ((np.sum((2 * index - n  - 1) * array)) / (n * np.sum(array))) #Gini coefficient"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Just to demonstrate, let's make a very unequal array:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "np.concatenate((np.zeros(99), np.ones(1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The gini coefficient should be close to 1:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "gini(np.concatenate((np.zeros(99), np.ones(1))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What if we have half zeroes and half ones?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "gini(np.concatenate((np.zeros(50), np.ones(50))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All ones?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "gini(np.ones(50))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can use the `gini` function on *Othello* to see how evenly distributed centrality is:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "gini(network_tab['Eigenvector Centrality'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great, but that's not terribly interesting itself, we want to see how it relates to other plays. We'll do that for homework. \n",
    "\n",
    "First, let's write a function to calculate Algee-Hewitt's second measure. He takes the percentage of characters in the top quartile of eigenvector centralities. You'll want to use the `np.percentile` method!\n",
    "\n",
    "## Challenge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def percentage_top_quartile(character_table):\n",
    "    # YOUR CODE HERE\n",
    "    \n",
    "    return percentage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "percentage_top_quartile(network_tab['Eigenvector Centrality'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework\n",
    "\n",
    "I've downloaded 40 other Shakespeare texts in the exact same XML structure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "!ls shakespeare_data/plays_xml/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write some code to loop through at least 5 of these plays and print the most central character in each play according to eigenvector centrality:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now use the `gini` function to calculate the gini coefficient of the eigenvector centralities for each of the 5 plays and create a bar chart. Do the same for the percentage in the top quartile. What do these results mean?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Much of this code is adapted from http://www.adampalay.com/blog/2015/04/17/shakespeare-social-networks/ ."
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
